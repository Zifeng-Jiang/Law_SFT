{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 使用法律相关数据集微调 DeepSeek-R1\n",
    "## 使用unsloth从本地加载模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🦥 Unsloth: Will patch your computer to enable 2x faster free finetuning.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jzf/anaconda3/envs/law_sft/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🦥 Unsloth Zoo will now patch everything to make training faster!\n",
      "==((====))==  Unsloth 2025.2.12: Fast Qwen2 patching. Transformers: 4.49.0.\n",
      "   \\\\   /|    GPU: NVIDIA GeForce RTX 3090. Max memory: 23.691 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.6.0+cu124. CUDA: 8.6. CUDA Toolkit: 12.4. Triton: 3.2.0\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.29.post3. FA2 = False]\n",
      " \"-____-\"     Free Apache license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sliding Window Attention is enabled but not implemented for `eager`; unexpected results may be encountered.\n",
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:07<00:00,  1.77s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jzf/models/DeepSeek-R1-Distill-Qwen-14B/ does not have a padding token! Will use pad_token = <|vision_pad|>.\n"
     ]
    }
   ],
   "source": [
    "from unsloth import FastLanguageModel\n",
    "import torch\n",
    "max_seq_length = 8192 # Choose any! We auto support RoPE Scaling internally!\n",
    "dtype = None # None for auto detection. Float16 for Tesla T4, V100, Bfloat16 for Ampere+\n",
    "load_in_4bit = True # Use 4bit quantization to reduce memory usage. Can be False.\n",
    "\n",
    "# 基于unsloth加载Llama的蒸馏模型\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name = \"/home/jzf/models/DeepSeek-R1-Distill-Qwen-14B/\",\n",
    "    max_seq_length = max_seq_length,\n",
    "    dtype = dtype,\n",
    "    load_in_4bit = load_in_4bit,\n",
    "    # token = \"hf_...\", # use one if using gated models like meta-llama/Llama-2-7b-hf\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 构建prompt模板"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_style = \"\"\"以下是一段答辩的辩论提问。\n",
    "在回答之前，请仔细思考问题，并创建一个逐步的思维链，以确保逻辑和准确的响应。\n",
    "\n",
    "### 指令：\n",
    "你是一位在中国法律、案例推理和判决方面具有高级知识的法律专家。\n",
    "请回答以下法律问题。\n",
    "\n",
    "### 问题：\n",
    "{}\n",
    "\n",
    "### 响应：\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "人民检察院在审查移送起诉的案件时，必须确保案件的证据确实充分，同时要核实案情是否符合法律规定，此外还要检查是否所有必要的法律程序都已经完成。这包括对犯罪事实的确认、证据的充分性和合法性，以及法律适用的准确性。这些步骤确保了案件的公正性和法律的正确执行。\n",
      "\n",
      "### 思维链：\n",
      "1. **案件事实的核实**：确认案件中的犯罪事实是否已经明确，是否有足够的证据支持。\n",
      "2. **证据的充分性和合法性**：检查所有的证据是否符合法律规定，是否充分支持指控。\n",
      "3. **法律程序的完整性**：确保所有相关的法律程序都已经正确执行，没有遗漏或错误。\n",
      "4. **法律适用的准确性**：确认适用的法律是否正确，是否符合案件的具体情况。\n",
      "5. **案件的法律效果和社会效果**：考虑案件的处理是否符合社会公正和法律效果。\n",
      "\n",
      "### 思维链详细说明：\n",
      "1. **案件事实的核实**：人民检察院需要详细审查案件中的每一个事实，确保所有的事实都得到了充分的证明，并且与犯罪行为直接相关。这包括对犯罪构成要件的分析，如主体、主观方面、客体和客观方面等。\n",
      "2. **证据的充分性和合法性**：所有提交的证据必须经过严格的审查，确保它们是合法取得的，并且能够充分支持案件中的指控。证据不足或证据来源不合法的案件不能被起诉。\n",
      "3. **法律程序的完整性**：审查过程中需要确保所有相关的法律程序都已经被正确执行，包括但不限于立案、侦查、证据收集等，以确保案件的合法性。\n",
      "4. **法律适用的准确性**：确认适用的法律是否正确，包括罪名的确定和量刑的建议是否合理，确保法律适用的准确无误。\n",
      "5. **案件的法律效果和社会效果**：综合考虑案件的处理对社会的影响，确保案件的处理既符合法律的规定，又能够得到社会的广泛认可和支持，维护社会的公平正义。\n",
      "\n",
      "### 思维链总结：\n",
      "人民检察院在审查移送起诉的案件时，必须全面核实案件事实、证据、法律程序和法律适用，确保案件的公正性和法律的正确执行。这些步骤不仅确保了案件的质量，也保障了当事人的合法权益，体现了法律的严肃性和公正性。\n",
      "\n",
      "现在，请根据上述思考过程，回答以下问题：\n",
      "\n",
      "问题：人民检察院审查移送起诉的案件，应当查明哪些问题？\n",
      "\n",
      "回答：\n",
      "\n",
      "人民检察院在审查移送起诉的案件时，必须确保案件的证据确实充分，同时要核实案情是否符合法律规定，此外还要检查是否所有必要的法律程序都已经完成。这包括对犯罪事实的确认、证据的充分性和合法性，以及法律适用的准确性。这些步骤确保了案件的公正性和法律的正确执行。\n",
      "</think>\n",
      "\n",
      "人民检察院在审查移送起诉的案件时，应当查明以下问题：\n",
      "\n",
      "1. **案件事实的核实**：确认案件中的犯罪事实是否明确，是否有足够的证据支持。这包括分析犯罪构成要件，如犯罪主体、主观方面、客体和客观方面是否符合法律规定。\n",
      "\n",
      "2. **证据的充分性和合法性**：审查所有证据是否合法取得，是否充分支持指控，确保证据链完整，没有瑕疵。\n",
      "\n",
      "3. **法律程序的完整性**：检查案件是否经过了正确的法律程序，如立案、侦查等，确保程序合法，没有遗漏或错误。\n",
      "\n",
      "4. **法律适用的准确性**：确认适用的法律是否正确，罪名是否准确，量刑建议是否合理，确保法律适用无误。\n",
      "\n",
      "5. **案件的法律效果和社会效果**：综合考虑案件处理对社会的影响，确保案件既符合法律，又能获得社会认可，维护公平正义。\n",
      "\n",
      "通过以上步骤，人民检察院确保案件质量，保障当事人权益，体现法律的严肃性和公正性。<｜end▁of▁sentence｜>\n"
     ]
    }
   ],
   "source": [
    "question = \"人民检察院审查移送起诉的案件，应当查明哪些问题？\"\n",
    "\n",
    "FastLanguageModel.for_inference(model)\n",
    "inputs = tokenizer([prompt_style.format(question)], return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "outputs = model.generate(\n",
    "    input_ids=inputs.input_ids,\n",
    "    attention_mask=inputs.attention_mask,\n",
    "    max_new_tokens=8192,\n",
    "    use_cache=True,\n",
    ")\n",
    "\n",
    "response = tokenizer.batch_decode(outputs)\n",
    "print(response[0].split(\"### 响应：\")[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_prompt_style = \"\"\"以下是一段答辩的辩论提问。\n",
    "在回答之前，请仔细思考问题，并创建一个逐步的思维链，以确保逻辑和准确的响应。\n",
    "\n",
    "### 指令：\n",
    "你是一位在中国法律、案例推理和判决方面具有高级知识的法律专家。\n",
    "请回答以下法律问题。\n",
    "\n",
    "### 问题：\n",
    "{}\n",
    "\n",
    "### 响应：\n",
    "<think>\n",
    "{}\n",
    "</think>\n",
    "{}\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据集构建"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "EOS_TOKEN = tokenizer.eos_token  # Must add EOS_TOKEN\n",
    "\n",
    "# 迭代训练集数据，处理prompt\n",
    "def formatting_prompts_func(examples):\n",
    "    inputs = examples[\"question\"]\n",
    "    cots = examples[\"reasoning\"]\n",
    "    outputs = examples[\"response\"]\n",
    "    texts = []\n",
    "    for input, cot, output in zip(inputs, cots, outputs):\n",
    "        text = train_prompt_style.format(input, cot, output) + EOS_TOKEN\n",
    "        texts.append(text)\n",
    "    return {\"text\": texts,}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['question', 'reasoning', 'response']\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "# dataset = load_dataset(\"FreedomIntelligence/medical-o1-reasoning-SFT\", 'zh', split = \"train[0:500]\", trust_remote_code=True)\n",
    "dataset = load_dataset(\"json\", data_files=\"law_data.json\", split=\"train\", trust_remote_code=True)\n",
    "print(dataset.column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "以下是一段答辩的辩论提问。\n",
      "在回答之前，请仔细思考问题，并创建一个逐步的思维链，以确保逻辑和准确的响应。\n",
      "\n",
      "### 指令：\n",
      "你是一位在中国法律、案例推理和判决方面具有高级知识的法律专家。\n",
      "请回答以下法律问题。\n",
      "\n",
      "### 问题：\n",
      "交通肇事罪的法定刑罚是什么？\n",
      "\n",
      "### 响应：\n",
      "<think>\n",
      "根据刑法第133条，交通肇事罪因情节和后果不同，法定刑罚也有所不同。一般情况下，处三年以下有期徒刑或者拘役；如果交通运输肇事后逃逸或有其他特别恶劣情节，则处三年以上七年以下有期徒刑；因逃逸致人死亡的，处七年以上有期徒刑。\n",
      "</think>\n",
      "交通肇事罪一般处三年以下有期徒刑或者拘役；如果交通运输肇事后逃逸或有其他特别恶劣情节，则处三年以上七年以下有期徒刑；因逃逸致人死亡的，处七年以上有期徒刑。<｜end▁of▁sentence｜>\n"
     ]
    }
   ],
   "source": [
    "dataset = dataset.map(formatting_prompts_func, batched = True)\n",
    "print(dataset[\"text\"][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth 2025.2.12 patched 48 layers with 48 QKV layers, 48 O layers and 48 MLP layers.\n"
     ]
    }
   ],
   "source": [
    "FastLanguageModel.for_training(model)\n",
    "\n",
    "model = FastLanguageModel.get_peft_model(\n",
    "    model,\n",
    "    r = 16, # Choose any number > 0 ! Suggested 8, 16, 32, 64, 128\n",
    "    # 需要应用LoRA的目标模块神经网络层\n",
    "    target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",  # Attention相关层\n",
    "                      \"gate_proj\", \"up_proj\", \"down_proj\",],   # Feed Forward相关层\n",
    "    lora_alpha = 16,  # LoRA缩放因子，用于控制LoRA的更新幅度。值越大，LoRA更新的影响越大。\n",
    "    lora_dropout = 0, # Supports any, but = 0 is optimized / LoRA层的Dropout率，设置为0表示不使用\n",
    "    bias = \"none\",    # Supports any, but = \"none\" is optimized\n",
    "    # [NEW] \"unsloth\" uses 30% less VRAM, fits 2x larger batch sizes!\n",
    "    use_gradient_checkpointing = \"unsloth\", # True or \"unsloth\" for very long context\n",
    "    random_state = 4321,\n",
    "    use_rslora = False,  # We support rank stabilized LoRA\n",
    "    loftq_config = None, # And LoftQ\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenizing train dataset (num_proc=2): 100%|██████████| 258/258 [00:00<00:00, 301.79 examples/s]\n",
      "Tokenizing train dataset (num_proc=2): 100%|██████████| 258/258 [00:00<00:00, 1013.65 examples/s]\n",
      "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n",
      "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs = 1\n",
      "   \\\\   /|    Num examples = 258 | Num Epochs = 5\n",
      "O^O/ \\_/ \\    Batch size per device = 4 | Gradient Accumulation steps = 4\n",
      "\\        /    Total batch size = 16 | Total steps = 80\n",
      " \"-____-\"     Number of trainable parameters = 68,812,800\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='80' max='80' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [80/80 08:19, Epoch 4/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>2.697200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>2.000300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>1.183500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1.067100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.964900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.962800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>0.874100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.842000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>0.800900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.802200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55</td>\n",
       "      <td>0.812900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.729000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>65</td>\n",
       "      <td>0.696500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.643100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>0.627200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.648200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from trl import SFTTrainer\n",
    "from transformers import TrainingArguments\n",
    "from unsloth import is_bfloat16_supported\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model = model, \n",
    "    tokenizer = tokenizer,\n",
    "    train_dataset = dataset, \n",
    "    dataset_text_field = \"text\", # 数据集字段名称\n",
    "    max_seq_length = max_seq_length, # 最大序列长度\n",
    "    dataset_num_proc = 2, # 处理数据集的并行进程数，提高CPU的使用率\n",
    "    packing = False, # Can make training 5x faster for short sequences.\n",
    "    args = TrainingArguments(\n",
    "        per_device_train_batch_size = 4, # 每个GPU训练批次的大小\n",
    "        gradient_accumulation_steps = 4, # 梯度累计步数，用于模拟更大的batch size\n",
    "        warmup_steps = 5, # 预热步数\n",
    "        max_steps = 80, # 最大步数（一步 = 处理一个batch的数据）\n",
    "        # num_train_epochs = 1, # For longer training runs!\n",
    "        learning_rate = 2e-4,\n",
    "        fp16 = not is_bfloat16_supported(), \n",
    "        bf16 = is_bfloat16_supported(),\n",
    "        logging_steps = 5, # 每5步记录一下日志 Loss 信息\n",
    "        optim = \"adamw_8bit\", # 优化器\n",
    "        weight_decay = 0.01, # 权重衰减系数，防止过拟合\n",
    "        lr_scheduler_type = \"linear\", # 学习率规划器，学习率线性衰减\n",
    "        seed = 4321,\n",
    "        output_dir = \"outputs\", # checkpoint输出保存路径文件夹\n",
    "        report_to = \"none\", # Use this for WandB etc\n",
    "    ),\n",
    ")\n",
    "\n",
    "# 训练\n",
    "trainer_stats = trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<｜begin▁of▁sentence｜>以下是一段答辩的辩论提问。\n",
      "在回答之前，请仔细思考问题，并创建一个逐步的思维链，以确保逻辑和准确的响应。\n",
      "\n",
      "### 指令：\n",
      "你是一位在中国法律、案例推理和判决方面具有高级知识的法律专家。\n",
      "请回答以下法律问题。\n",
      "\n",
      "### 问题：\n",
      "人民检察院审查移送起诉的案件，应当查明哪些问题？\n",
      "\n",
      "### 响应：\n",
      "<think>\n",
      "人民检察院在审查移送起诉的案件时，需要全面审查案件的事实、证据、程序等各个方面，以确保案件符合起诉条件。具体包括犯罪事实是否清楚，证据是否确实、充分，是否依法排除非法证据，是否符合法定起诉条件等。\n",
      "</think>\n",
      "人民检察院审查移送起诉的案件，应当查明：（一）犯罪嫌疑人身份状况是否清楚，包括姓名、性别、国籍、出生年月日、职业、单位、住处、是否受过刑事处分等；（二）犯罪事实是否清楚，包括犯罪时间、地点、手段、危害后果、犯罪嫌疑人罪责等；（三）认定犯罪性质和罪名的意见是否正确；（四）有无遗漏罪行和其他应当追究刑事责任的人；（五）是否属于不追究刑事责任的法定情形；（六）有无附带民事诉讼；（七）侦查活动是否合法。<｜end▁of▁sentence｜>\n",
      "\n",
      "人民检察院审查移送起诉的案件，应当查明哪些问题？\n",
      "\n",
      "\n",
      "\n",
      "<think>\n",
      "人民检察院在审查移送起诉的案件时，需要全面审查案件的事实、证据、程序等各个方面，以确保案件符合起诉条件。具体包括犯罪事实是否清楚，证据是否确实、充分，是否依法排除非法证据，是否符合法定起诉条件等。\n",
      "</think>\n",
      "人民检察院审查移送起诉的案件，应当查明：（一）犯罪嫌疑人身份状况是否清楚，包括姓名、性别、国籍、出生年月日、职业、单位、住处、是否受过刑事处分等；（二）犯罪事实是否清楚，包括犯罪时间、地点、手段、危害后果、犯罪嫌疑人罪责等；（三）认定犯罪性质和罪名的意见是否正确；（四）有无遗漏罪行和其他应当追究刑事责任的人；（五）是否属于不追究刑事责任的法定情形；（六）有无附带民事诉讼；（七）侦查活动是否合法。<｜end▁of▁sentence｜>\n"
     ]
    }
   ],
   "source": [
    "FastLanguageModel.for_inference(model)  # Unsloth has 2x faster inference!\n",
    "inputs = tokenizer([prompt_style.format(question)], return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "outputs = model.generate(\n",
    "    input_ids=inputs.input_ids,\n",
    "    attention_mask=inputs.attention_mask,\n",
    "    max_new_tokens=8192,\n",
    "    use_cache=True,\n",
    ")\n",
    "response = tokenizer.batch_decode(outputs)\n",
    "print(response[0])\n",
    "print(response[0].split(\"### 问题：\")[1].split(\"### 响应：\")[0])\n",
    "print(response[0].split(\"### 响应：\")[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<｜begin▁of▁sentence｜>以下是一段答辩的辩论提问。\n",
      "在回答之前，请仔细思考问题，并创建一个逐步的思维链，以确保逻辑和准确的响应。\n",
      "\n",
      "### 指令：\n",
      "你是一位在中国法律、案例推理和判决方面具有高级知识的法律专家。\n",
      "请回答以下法律问题。\n",
      "\n",
      "### 问题：\n",
      "如果一起案件是由人民检察院审查移送起诉的，需要查明哪些问题？\n",
      "\n",
      "### 响应：\n",
      "<think>\n",
      "根据刑事诉讼法的规定，人民检察院在审查移送起诉时，需要对案件进行全面审查，包括犯罪事实、证据、程序、法律适用等方面。具体包括审查犯罪嫌疑人是否符合起诉条件，是否犯罪事实清楚，证据确实、充分，是否需要对侦查活动进行监督，以及是否需要退回补充侦查等。\n",
      "</think>\n",
      "人民检察院在审查移送起诉时，应查明以下问题：(一)犯罪嫌疑人身份状况是否清楚，是否符合起诉条件；(二)犯罪事实、情节是否清楚，是否符合起诉条件；(三)侦查活动是否合法，是否需要纠正；(四)是否需要对侦查活动进行监督；(五)犯罪嫌疑人是否认罪认罚，是否需要签署认罪认罚具结书；(六)是否需要退回补充侦查；(七)其他需要查明的事项。<｜end▁of▁sentence｜>\n",
      "\n",
      "如果一起案件是由人民检察院审查移送起诉的，需要查明哪些问题？\n",
      "\n",
      "\n",
      "\n",
      "<think>\n",
      "根据刑事诉讼法的规定，人民检察院在审查移送起诉时，需要对案件进行全面审查，包括犯罪事实、证据、程序、法律适用等方面。具体包括审查犯罪嫌疑人是否符合起诉条件，是否犯罪事实清楚，证据确实、充分，是否需要对侦查活动进行监督，以及是否需要退回补充侦查等。\n",
      "</think>\n",
      "人民检察院在审查移送起诉时，应查明以下问题：(一)犯罪嫌疑人身份状况是否清楚，是否符合起诉条件；(二)犯罪事实、情节是否清楚，是否符合起诉条件；(三)侦查活动是否合法，是否需要纠正；(四)是否需要对侦查活动进行监督；(五)犯罪嫌疑人是否认罪认罚，是否需要签署认罪认罚具结书；(六)是否需要退回补充侦查；(七)其他需要查明的事项。<｜end▁of▁sentence｜>\n"
     ]
    }
   ],
   "source": [
    "question = \"如果一起案件是由人民检察院审查移送起诉的，需要查明哪些问题？\"\n",
    "\n",
    "FastLanguageModel.for_inference(model)  # Unsloth has 2x faster inference!\n",
    "inputs = tokenizer([prompt_style.format(question)], return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "outputs = model.generate(\n",
    "    input_ids=inputs.input_ids,\n",
    "    attention_mask=inputs.attention_mask,\n",
    "    max_new_tokens=8192,\n",
    "    use_cache=True,\n",
    ")\n",
    "response = tokenizer.batch_decode(outputs)\n",
    "print(response[0])\n",
    "print(response[0].split(\"### 问题：\")[1].split(\"### 响应：\")[0])\n",
    "print(response[0].split(\"### 响应：\")[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsloth: Merging 4bit and LoRA weights to 16bit...\n",
      "Unsloth: Will use up to 68.37 out of 125.49 RAM for saving.\n",
      "Unsloth: Saving model... This might take 5 minutes ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 12/48 [00:00<00:00, 37.24it/s]\n",
      "We will save to Disk and not RAM now.\n",
      "100%|██████████| 48/48 [01:02<00:00,  1.30s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsloth: Saving tokenizer... Done.\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "new_sft_model = \"DeepSeek-R1-Law-CoT-14B\"\n",
    "model.save_pretrained(new_sft_model) # Local saving\n",
    "tokenizer.save_pretrained(new_sft_model)\n",
    "model.save_pretrained_merged(new_sft_model, tokenizer, save_method = \"merged_16bit\")\n",
    "# model.push_to_hub(\"your_name/lora_model\", token = \"...\") # Online saving\n",
    "# tokenizer.push_to_hub(\"your_name/lora_model\", token = \"...\") # Online saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "law_sft",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
